{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af639b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukelo/miniconda3/envs/sanza/lib/python3.10/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'HSI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m cubes, wn_all \u001b[38;5;241m=\u001b[39m [], \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m mat_paths:\n\u001b[0;32m---> 49\u001b[0m     cube, wn \u001b[38;5;241m=\u001b[39m \u001b[43mload_cube_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     cubes\u001b[38;5;241m.\u001b[39mappend(cube)               \u001b[38;5;66;03m# (C,H,W)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wn_all \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: wn_all \u001b[38;5;241m=\u001b[39m wn   \u001b[38;5;66;03m# nimm die erste WL-Liste als Referenz\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m, in \u001b[0;36mload_cube_mat\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLädt .mat -> (cube: (C,H,W) float32, wn: (C,) int)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m mat \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mloadmat(path)\n\u001b[0;32m---> 25\u001b[0m HSI \u001b[38;5;241m=\u001b[39m \u001b[43mmat\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHSI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)              \u001b[38;5;66;03m# (H,W,C)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m H, W, C \u001b[38;5;241m=\u001b[39m HSI\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     27\u001b[0m cube \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(HSI)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()  \u001b[38;5;66;03m# -> (C,H,W)\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HSI'"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Fastai-Training: 1 Band -> restliche (C-1) Bänder\n",
    "# Daten-Layout: HSI (H,W,C)= (260,1500,49)   wn = [760..1240]nm in 10nm-Schritten\n",
    "# ==============================================\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import torch, numpy as np, scipy.io, glob, random\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Hardware-Optimierung\n",
    "# -----------------------------\n",
    "torch.backends.cudnn.benchmark = True                 # schnellere CuDNN-Auswahl für konstante Input-Shapes\n",
    "if hasattr(torch, \"set_float32_matmul_precision\"):\n",
    "    torch.set_float32_matmul_precision(\"high\")        # bessere (und oft schnellere) GEMMs\n",
    "device = default_device()                             # fastai-Gerät (cuda, wenn vorhanden)\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Utils: MAT-Laden & WL-Mapping\n",
    "# -----------------------------\n",
    "def load_cube_mat(path:Path):\n",
    "    \"Lädt .mat -> (cube: (C,H,W) float32, wn: (C,) int)\"\n",
    "    mat = scipy.io.loadmat(path)\n",
    "    HSI = mat[\"HSI\"].astype(np.float32)              # (H,W,C)\n",
    "    H, W, C = HSI.shape\n",
    "    cube = torch.from_numpy(HSI).permute(2,0,1).contiguous()  # -> (C,H,W)\n",
    "    wn = mat.get(\"wn\", None)\n",
    "    if wn is not None:\n",
    "        wn = torch.from_numpy(wn.reshape(-1).astype(np.int32))  # (C,)\n",
    "    else:\n",
    "        wn = torch.arange(760, 760+10*C, 10, dtype=torch.int32) # Fallback\n",
    "    return cube, wn\n",
    "\n",
    "def band_index_from_nm(wn_vec:torch.Tensor, nm:int) -> int:\n",
    "    \"Nimmt das **nächstgelegene** Band zur gewünschten Wellenlänge\"\n",
    "    return int(torch.argmin(torch.abs(wn_vec - int(nm))).item())\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Daten einsammeln\n",
    "# -----------------------------\n",
    "data_dir = Path(\"data\")\n",
    "mat_paths = sorted(glob.glob(str(data_dir/\"*.mat\")))\n",
    "assert len(mat_paths)>0, \"Keine .mat-Dateien in data/ gefunden.\"\n",
    "\n",
    "# wir laden alle Cubes in Liste (für größere Datensätze könntest du lazy-laden)\n",
    "cubes, wn_all = [], None\n",
    "for p in mat_paths:\n",
    "    cube, wn = load_cube_mat(Path(p))\n",
    "    cubes.append(cube)               # (C,H,W)\n",
    "    if wn_all is None: wn_all = wn   # nimm die erste WL-Liste als Referenz\n",
    "\n",
    "C, H, W = cubes[0].shape\n",
    "print(f\"Gelesen: {len(cubes)} Cubes, Shape je (C,H,W)=({C},{H},{W})\")\n",
    "print(\"Wellenlängen (erste/letzte):\", int(wn_all[0]), int(wn_all[-1]))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Bandauswahl (deine Präferenzen)\n",
    "#    Wunschliste: 550nm (Grün), 800nm (NIR), 1550nm (SWIR)\n",
    "#    -> wir mappen auf das nächste im Datensatz verfügbare Band\n",
    "# -----------------------------\n",
    "desired_nms = [550, 800, 1550]\n",
    "mapped = [(nm, int(wn_all[band_index_from_nm(wn_all, nm)])) for nm in desired_nms]\n",
    "print(\"Band-Mapping (gewünscht -> genutzt):\", mapped)\n",
    "\n",
    "# setze das aktive Eingabeband (nimm eins der gemappten)\n",
    "input_nm_desired = 800                 # <- hier kannst du 550/800/1550 testen\n",
    "band_idx = band_index_from_nm(wn_all, input_nm_desired)\n",
    "print(f\"Gewünschtes Band {input_nm_desired}nm -> benutze {int(wn_all[band_idx])}nm (Index {band_idx})\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Bandweise Normalisierung bestimmen (nur aus Train-Cubes)\n",
    "#     - robust: Schätzung über zufällige Patches\n",
    "# -----------------------------\n",
    "def estimate_minmax(cubes, ps=128, draws=400):\n",
    "    mins, maxs = [], []\n",
    "    for _ in range(draws):\n",
    "        cube = random.choice(cubes)   # (C,H,W)\n",
    "        _, Hc, Wc = cube.shape\n",
    "        if Hc<ps or Wc<ps: continue\n",
    "        y0 = random.randint(0, Hc-ps)\n",
    "        x0 = random.randint(0, Wc-ps)\n",
    "        patch = cube[:, y0:y0+ps, x0:x0+ps]\n",
    "        mins.append(patch.view(C,-1).min(dim=1).values)\n",
    "        maxs.append(patch.view(C,-1).max(dim=1).values)\n",
    "    mins = torch.stack(mins,0).min(0).values\n",
    "    maxs = torch.stack(maxs,0).max(0).values\n",
    "    return mins, maxs\n",
    "\n",
    "mins, maxs = estimate_minmax(cubes, ps=128, draws=400)\n",
    "eps = 1e-8\n",
    "\n",
    "def norm_cube(cube):\n",
    "    \"Bandweise Min-Max Normalisierung mit stabilen Schätzern\"\n",
    "    return (cube - mins.view(-1,1,1)) / (maxs.view(-1,1,1) - mins.view(-1,1,1) + eps)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Dataset: zufällige Patches (x=1 Band, y=C-1 Bänder)\n",
    "# -----------------------------\n",
    "class HSIPatchDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, cubes, band_idx:int, ps=128, n_patches=4000):\n",
    "        self.cubes, self.k = cubes, band_idx\n",
    "        self.ps, self.n = ps, n_patches\n",
    "\n",
    "    def __len__(self): return self.n\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        cube = random.choice(self.cubes)               # (C,H,W)\n",
    "        C,H,W = cube.shape\n",
    "        y0 = random.randint(0, H-self.ps)\n",
    "        x0 = random.randint(0, W-self.ps)\n",
    "        patch = norm_cube(cube)[:, y0:y0+self.ps, x0:x0+self.ps] # normiert\n",
    "        x = patch[self.k:self.k+1]                     # (1,ps,ps)  -> Eingabeband\n",
    "        y = torch.cat([patch[:self.k], patch[self.k+1:]], dim=0) # (C-1,ps,ps)\n",
    "        return x, y\n",
    "\n",
    "# Train/Valid Datasets & DataLoaders (fastai)\n",
    "train_ds = HSIPatchDS(cubes, band_idx, ps=128, n_patches=6000)\n",
    "valid_ds = HSIPatchDS(cubes, band_idx, ps=128, n_patches=800)\n",
    "\n",
    "# DataLoaders mit pin_memory, num_workers und channels_last\n",
    "train_dl = DataLoader(train_ds, batch_size=8, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "dls = DataLoaders(train_dl, valid_dl).cuda()\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Loss & Metriken: MSE + SAM\n",
    "# -----------------------------\n",
    "class SAMLoss(Module):\n",
    "    \"Spectral Angle Mapper als Loss (je Pixel), gemittelt.\"\n",
    "    def __init__(self, eps=1e-8): self.eps = eps\n",
    "    def forward(self, pred, targ):\n",
    "        # pred, targ: (B,C,H,W)\n",
    "        B,C,H,W = pred.shape\n",
    "        P = rearrange(pred, 'b c h w -> (b h w) c')\n",
    "        T = rearrange(targ, 'b c h w -> (b h w) c')\n",
    "        num = (P*T).sum(dim=1)\n",
    "        den = (P.norm(dim=1)*T.norm(dim=1)).clamp_min(self.eps)\n",
    "        cos = (num/den).clamp(-1+1e-6, 1-1e-6)\n",
    "        ang = torch.acos(cos)\n",
    "        return ang.mean()\n",
    "\n",
    "class CombinedLoss(Module):\n",
    "    \"0.7*MSE + 0.3*SAM (Startwerte; gerne tunen)\"\n",
    "    def __init__(self, w_mse=0.7, w_sam=0.3):\n",
    "        self.mse = MSELossFlat()\n",
    "        self.sam = SAMLoss()\n",
    "        self.w_mse, self.w_sam = w_mse, w_sam\n",
    "    def forward(self, pred, targ):\n",
    "        return self.w_mse*self.mse(pred, targ) + self.w_sam*self.sam(pred, targ)\n",
    "\n",
    "# Metriken für Validation\n",
    "def sam_metric(pred, targ): return SAMLoss()(pred, targ)\n",
    "def rmse_metric(pred, targ): return torch.sqrt(F.mse_loss(pred, targ))\n",
    "def psnr_metric(pred, targ, data_range=1.0, eps=1e-8):\n",
    "    mse = F.mse_loss(pred, targ)\n",
    "    return 20. * torch.log10(data_range / torch.sqrt(mse + eps))\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Modell: fastai Unet mit ResNet-Encoder\n",
    "#     - n_in=1 (ein Eingangskanal: das gewählte Band)\n",
    "#     - n_out=C-1 (alle anderen Bänder)\n",
    "#     - y_range=(0,1): SigmoidRange-Klammerung für normierte Targets\n",
    "# -----------------------------\n",
    "arch = resnet34\n",
    "learn = unet_learner(\n",
    "    dls, arch,\n",
    "    n_in=1,                    # wir geben 1 Kanal rein (gewähltes Band)\n",
    "    n_out=C-1,                 # wir wollen C-1 Bänder schätzen\n",
    "    y_range=(0,1),             # Targets sind [0,1] nach Normierung\n",
    "    loss_func=CombinedLoss(),\n",
    "    metrics=[sam_metric, rmse_metric, psnr_metric]\n",
    ")\n",
    "\n",
    "# Channels-last für effiziente Tensor-Layouts (oft schneller auf Ampere+)\n",
    "for m in learn.model.modules():\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        m.weight.data = m.weight.data.to(memory_format=torch.channels_last)\n",
    "learn.model = learn.model.to(memory_format=torch.channels_last)\n",
    "\n",
    "# Mixed Precision (FP16) für Speed auf GPU\n",
    "learn = learn.to_fp16()\n",
    "\n",
    "# PyTorch 2.x Compiler (bei CUDA 11.8+/PyTorch>=2.0)\n",
    "try:\n",
    "    learn.model = torch.compile(learn.model, mode=\"max-autotune\")\n",
    "    print(\"torch.compile aktiviert.\")\n",
    "except Exception as e:\n",
    "    print(\"torch.compile nicht verfügbar:\", e)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Training\n",
    "# -----------------------------\n",
    "# 1) Optional: LR-Finder\n",
    "# learn.lr_find()\n",
    "\n",
    "# 2) Haupttraining\n",
    "learn.fine_tune(\n",
    "    20,                    # Epochen\n",
    "    base_lr=3e-4,          # Start-LR (tunen!)\n",
    "    cbs=[\n",
    "        SaveModelCallback(monitor='valid_loss', fname='best'),\n",
    "        EarlyStoppingCallback(monitor='valid_loss', patience=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Export & Beispiel-Inferenz (ein großer Crop)\n",
    "# -----------------------------\n",
    "learn.export(\"hsi_unet_1toRest_fastai.pkl\")\n",
    "print(\"Model exported: hsi_unet_1toRest_fastai.pkl\")\n",
    "\n",
    "# Inferenz-Demo (großer Crop aus erstem Cube)\n",
    "with torch.no_grad():\n",
    "    cube0 = cubes[0]              # (C,H,W)\n",
    "    ps = min(256, cube0.shape[1], cube0.shape[2])\n",
    "    y0 = max((cube0.shape[1]-ps)//2, 0)\n",
    "    x0 = max((cube0.shape[2]-ps)//2, 0)\n",
    "    big = norm_cube(cube0)[:, y0:y0+ps, x0:x0+ps]\n",
    "    x_big = big[band_idx:band_idx+1].unsqueeze(0).to(device)        # (1,1,ps,ps)\n",
    "    y_true = torch.cat([big[:band_idx], big[band_idx+1:]],0)[None].to(device)  # (1,C-1,ps,ps)\n",
    "\n",
    "    pred = learn.model(x_big.half())                                 # FP16 fwd\n",
    "    # Metriken:\n",
    "    sam = sam_metric(pred.float(), y_true.float()).item()\n",
    "    rmse = rmse_metric(pred.float(), y_true.float()).item()\n",
    "    psnr = psnr_metric(pred.float(), y_true.float()).item()\n",
    "    print(f\"Demo-Crop @ {int(wn_all[band_idx])}nm | SAM={sam:.4f} rad | RMSE={rmse:.4f} | PSNR={psnr:.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d296f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
