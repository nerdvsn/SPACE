{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aeedac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eingabeband: 1000 nm -> index 24, wn[idx]=1000nm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Train/Val Datasets + Normalisierung aus Train\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m train_set_temp \u001b[38;5;241m=\u001b[39m \u001b[43mSingleBandToRestHSIPatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcube\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mband_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m mins, maxs \u001b[38;5;241m=\u001b[39m train_set_temp\u001b[38;5;241m.\u001b[39mget_stats()\n\u001b[1;32m     99\u001b[0m train_set \u001b[38;5;241m=\u001b[39m SingleBandToRestHSIPatches(cube, band_idx, patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, n_patches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, stats\u001b[38;5;241m=\u001b[39m(mins,maxs))\n",
      "Cell \u001b[0;32mIn[3], line 66\u001b[0m, in \u001b[0;36mSingleBandToRestHSIPatches.__init__\u001b[0;34m(self, cube_CHW, band_idx, patch_size, n_patches, split, stats)\u001b[0m\n\u001b[1;32m     64\u001b[0m x0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     65\u001b[0m patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcube[:, y0:y0\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mps, x0:x0\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mps]\n\u001b[0;32m---> 66\u001b[0m mn \u001b[38;5;241m=\u001b[39m \u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmin(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     67\u001b[0m mx \u001b[38;5;241m=\u001b[39m patch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     68\u001b[0m mins\u001b[38;5;241m.\u001b[39mappend(mn); maxs\u001b[38;5;241m.\u001b[39mappend(mx)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Single-Band -> Rest HSI Recon (PyTorch)\n",
    "# Daten: HSI (H,W,C) = (260,1500,49), wn (49,1) = [760..1240] nm\n",
    "# =========================\n",
    "import math, numpy as np, scipy.io\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ---------- 1) Daten laden ----------\n",
    "mat = scipy.io.loadmat(\"data/heatcube_0001.mat\")\n",
    "HSI = mat[\"HSI\"]             # (H,W,C) float64\n",
    "H, W, C = HSI.shape\n",
    "HSI = torch.from_numpy(HSI.astype(np.float32))  # -> float32\n",
    "# nach (C,H,W) transponieren\n",
    "cube = HSI.permute(2,0,1).contiguous()          # (C,H,W)\n",
    "\n",
    "# Wellenlängen laden (optional, für Auswahl per nm)\n",
    "# Falls in anderer MAT-Datei:\n",
    "# matLibWn = scipy.io.loadmat(\"data/wavelengths.mat\")  # Beispiel\n",
    "# wn = matLibWn[\"wn\"].reshape(-1)  # (49,)\n",
    "wn = mat.get(\"wn\", None)\n",
    "if wn is not None:\n",
    "    wn = torch.from_numpy(wn.astype(np.int32)).view(-1)  # (49,)\n",
    "else:\n",
    "    # Fallback: gleichmäßige 10-nm Schritte ab 760\n",
    "    wn = torch.arange(760, 760 + 10*C, 10, dtype=torch.int32)\n",
    "\n",
    "# ---------- 2) Eingabeband wählen ----------\n",
    "def band_index_from_nm(wn_vector, target_nm):\n",
    "    # nimmt nächstgelegene Wellenlänge\n",
    "    idx = int(torch.argmin(torch.abs(wn_vector - int(target_nm))).item())\n",
    "    return idx\n",
    "\n",
    "target_wavelength_nm = 1000  # <- hier ändern, z.B. 940, 1100, etc.\n",
    "band_idx = band_index_from_nm(wn, target_wavelength_nm)\n",
    "print(f\"Eingabeband: {target_wavelength_nm} nm -> index {band_idx}, wn[idx]={int(wn[band_idx])}nm\")\n",
    "\n",
    "# ---------- 3) Patch-Datensatz ----------\n",
    "class SingleBandToRestHSIPatches(Dataset):\n",
    "    def __init__(self, cube_CHW, band_idx, patch_size=128, n_patches=2000, split=\"train\", stats=None):\n",
    "        \"\"\"\n",
    "        cube_CHW: (C,H,W) Tensor\n",
    "        band_idx: int (Eingabeband)\n",
    "        patch_size: Größe der Quadrate\n",
    "        n_patches: Anzahl zufälliger Patches, die pro Epoch gezogen werden\n",
    "        split: \"train\" oder \"val\"\n",
    "        stats: (mins, maxs) für bandweise Min-Max (nur aus Train bestimmt)\n",
    "        \"\"\"\n",
    "        self.cube = cube_CHW\n",
    "        self.C, self.H, self.W = cube_CHW.shape\n",
    "        self.k = band_idx\n",
    "        self.ps = patch_size\n",
    "        self.n_patches = n_patches if split == \"train\" else max(n_patches//8, 256)\n",
    "        self.split = split\n",
    "\n",
    "        if stats is None and split == \"train\":\n",
    "            # bandweise Min/Max nur aus zufälligen Train-Patches schätzen\n",
    "            mins = []; maxs = []\n",
    "            with torch.no_grad():\n",
    "                for _ in range(200):\n",
    "                    y0 = torch.randint(0, self.H - self.ps + 1, (1,)).item()\n",
    "                    x0 = torch.randint(0, self.W - self.ps + 1, (1,)).item()\n",
    "                    patch = self.cube[:, y0:y0+self.ps, x0:x0+self.ps]\n",
    "                    mn = patch.view(self.C,-1).min(dim=1).values\n",
    "                    mx = patch.view(self.C,-1).max(dim=1).values\n",
    "                    mins.append(mn); maxs.append(mx)\n",
    "            mins = torch.stack(mins,0).min(0).values\n",
    "            maxs = torch.stack(maxs,0).max(0).values\n",
    "            self.mins, self.maxs = mins, maxs\n",
    "        else:\n",
    "            self.mins, self.maxs = (stats if stats is not None else (None, None))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_patches\n",
    "\n",
    "    def get_stats(self):\n",
    "        return self.mins, self.maxs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # zufälliger Patch (Train/Val)\n",
    "        y0 = torch.randint(0, self.H - self.ps + 1, (1,)).item()\n",
    "        x0 = torch.randint(0, self.W - self.ps + 1, (1,)).item()\n",
    "        patch = self.cube[:, y0:y0+self.ps, x0:x0+self.ps]  # (C,ps,ps)\n",
    "\n",
    "        # bandweise Min-Max\n",
    "        eps = 1e-8\n",
    "        if self.mins is not None and self.maxs is not None:\n",
    "            patch = (patch - self.mins.view(-1,1,1)) / (self.maxs.view(-1,1,1) - self.mins.view(-1,1,1) + eps)\n",
    "\n",
    "        x = patch[self.k:self.k+1]  # (1,ps,ps)\n",
    "        y = torch.cat([patch[:self.k], patch[self.k+1:]], dim=0)  # (C-1,ps,ps)\n",
    "        return x, y\n",
    "\n",
    "# Train/Val Datasets + Normalisierung aus Train\n",
    "train_set_temp = SingleBandToRestHSIPatches(cube, band_idx, patch_size=128, n_patches=1, split=\"train\")\n",
    "mins, maxs = train_set_temp.get_stats()\n",
    "train_set = SingleBandToRestHSIPatches(cube, band_idx, patch_size=128, n_patches=4000, split=\"train\", stats=(mins,maxs))\n",
    "val_set   = SingleBandToRestHSIPatches(cube, band_idx, patch_size=128, n_patches=800,  split=\"val\",   stats=(mins,maxs))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_set,   batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "# ---------- 4) Modell (kleines UNet-ähnliches CNN) ----------\n",
    "class SmallHSIRecon(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        ch = 48\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(1, ch, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.down = nn.Conv2d(ch, ch, 4, stride=2, padding=1)  # 1/2\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.up = nn.ConvTranspose2d(ch, ch, 4, stride=2, padding=1)  # x2\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch, out_channels, 3, padding=1),\n",
    "            nn.Softplus()   # Nichtnegativität; falls deine Daten zentriert sind, ersetze durch Identity\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.enc(x)\n",
    "        d = self.down(e)\n",
    "        b = self.bottleneck(d)\n",
    "        u = self.up(b)\n",
    "        if u.shape == e.shape:\n",
    "            u = u + e\n",
    "        y = self.dec(u)\n",
    "        return y\n",
    "\n",
    "# ---------- 5) Metriken ----------\n",
    "def spectral_angle_mapper(pred, target, eps=1e-8):\n",
    "    # pred/target: (B,C,H,W)\n",
    "    B, C, H, W = pred.shape\n",
    "    P = pred.permute(0,2,3,1).reshape(-1, C)\n",
    "    T = target.permute(0,2,3,1).reshape(-1, C)\n",
    "    num = (P*T).sum(1)\n",
    "    den = (P.norm(1) * T.norm(1)).clamp_min(eps)\n",
    "    cos = (num/den).clamp(-1+1e-6, 1-1e-6)\n",
    "    ang = torch.acos(cos)  # Radiant\n",
    "    return ang.mean()\n",
    "\n",
    "def rmse(pred, target):\n",
    "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
    "\n",
    "def psnr(pred, target, data_range=1.0, eps=1e-8):\n",
    "    mse = torch.mean((pred - target) ** 2)\n",
    "    return 20.0 * torch.log10(data_range / torch.sqrt(mse + eps))\n",
    "\n",
    "# ---------- 6) Training ----------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SmallHSIRecon(out_channels=C-1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    mse_sum = sam_sum = psnr_sum = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            mse_sum  += mse(y_hat, y).item() * x.size(0)\n",
    "            sam_sum  += spectral_angle_mapper(y_hat, y).item() * x.size(0)\n",
    "            psnr_sum += psnr(y_hat, y).item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "    return mse_sum/n, sam_sum/n, psnr_sum/n\n",
    "\n",
    "EPOCHS = 20\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    for x,y in train_loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = 0.7*mse(y_hat,y) + 0.3*spectral_angle_mapper(y_hat,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item() * x.size(0)\n",
    "\n",
    "    val_mse, val_sam, val_psnr = validate()\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={loss_sum/len(train_set):.4f} \"\n",
    "          f\"| val_mse={val_mse:.4f} | val_sam(rad)={val_sam:.4f} | val_psnr(dB)={val_psnr:.2f}\")\n",
    "\n",
    "# ---------- 7) Demo: vollständige Rekonstruktion auf großem Crop ----------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # großen Crop wählen (z.B. mittlerer 256x256 Bereich, falls möglich)\n",
    "    ps = 256\n",
    "    y0 = max((H-ps)//2, 0); x0 = max((W-ps)//2, 0)\n",
    "    big = cube[:, y0:y0+ps, x0:x0+ps].clone()  # (C,ps,ps)\n",
    "\n",
    "    # Normierung anwenden\n",
    "    eps = 1e-8\n",
    "    big_n = (big - mins.view(-1,1,1)) / (maxs.view(-1,1,1) - mins.view(-1,1,1) + eps)\n",
    "\n",
    "    x_big = big_n[band_idx:band_idx+1].unsqueeze(0).to(device)  # (1,1,ps,ps)\n",
    "    y_true = torch.cat([big_n[:band_idx], big_n[band_idx+1:]], dim=0).unsqueeze(0).to(device)  # (1,C-1,ps,ps)\n",
    "    y_pred = model(x_big)\n",
    "\n",
    "    demo_sam  = spectral_angle_mapper(y_pred, y_true).item()\n",
    "    demo_rmse = rmse(y_pred, y_true).item()\n",
    "    demo_psnr = psnr(y_pred, y_true).item()\n",
    "    print(f\"\\nDemo Crop Metrics @ {int(wn[band_idx])}nm input -> SAM={demo_sam:.4f} rad, RMSE={demo_rmse:.4f}, PSNR={demo_psnr:.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c12c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
